<!DOCTYPE HTML>
<html lang="cn" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Vincent教你学Generative AI (https://taohu.me/vincent-genai-course/) </title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="preface.html">前言</a></li><li class="chapter-item expanded "><a href="diffusion.html"><strong aria-hidden="true">1.</strong> 扩散模型(Diffusion Model)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion/basics.html"><strong aria-hidden="true">1.1.</strong> 理论基础</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion/basics/first_diffusion_paper.html"><strong aria-hidden="true">1.1.1.</strong> 从 Sol Dickenstein讲起</a></li><li class="chapter-item expanded "><a href="diffusion/basics/ddpm.html"><strong aria-hidden="true">1.1.2.</strong> DDPM</a></li><li class="chapter-item expanded "><a href="diffusion/basics/score-matching.html"><strong aria-hidden="true">1.1.3.</strong> Score Matching</a></li><li class="chapter-item expanded "><a href="diffusion/basics/score-sde.html"><strong aria-hidden="true">1.1.4.</strong> Score SDE</a></li><li class="chapter-item expanded "><a href="diffusion/basics/flow-matching.html"><strong aria-hidden="true">1.1.5.</strong> Flow Matching</a></li><li class="chapter-item expanded "><a href="diffusion/basics/stochastic-interpolants.html"><strong aria-hidden="true">1.1.6.</strong> Stochastic Interpolants</a></li></ol></li><li class="chapter-item expanded "><a href="diffusion/sampling.html"><strong aria-hidden="true">1.2.</strong> 采样方法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion/sampling/ode.html"><strong aria-hidden="true">1.2.1.</strong> ODE 采样方法</a></li><li class="chapter-item expanded "><a href="diffusion/sampling/DDIM.html"><strong aria-hidden="true">1.2.2.</strong> DDIM</a></li><li class="chapter-item expanded "><a href="diffusion/sampling/DPM.html"><strong aria-hidden="true">1.2.3.</strong> DPM</a></li></ol></li><li class="chapter-item expanded "><a href="diffusion/vae.html"><strong aria-hidden="true">1.3.</strong> ✅ VAE 相关的优化</a></li><li class="chapter-item expanded "><a href="diffusion/stable-diffusion.html"><strong aria-hidden="true">1.4.</strong> 稳定扩散模型(Stable Diffusion)</a></li><li class="chapter-item expanded "><a href="diffusion/consistency.html"><strong aria-hidden="true">1.5.</strong> 一致性模型(Consistency Models)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion/consistency/improved-consistency-models.html"><strong aria-hidden="true">1.5.1.</strong> improved consistency models</a></li><li class="chapter-item expanded "><a href="diffusion/consistency/simplified-consistency-models.html"><strong aria-hidden="true">1.5.2.</strong> Simplified Consistency Models</a></li></ol></li><li class="chapter-item expanded "><a href="diffusion/shortcut.html"><strong aria-hidden="true">1.6.</strong> ✅ Shorcut Models </a></li><li class="chapter-item expanded "><a href="diffusion/backbone.html"><strong aria-hidden="true">1.7.</strong> 骨干网络设计(Backbone Design)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion/backbone/transformer.html"><strong aria-hidden="true">1.7.1.</strong> Transformer</a></li><li class="chapter-item expanded "><a href="diffusion/backbone/unet.html"><strong aria-hidden="true">1.7.2.</strong> U-Net</a></li><li class="chapter-item expanded "><a href="diffusion/backbone/mamba.html"><strong aria-hidden="true">1.7.3.</strong> Mamba, RWKV, GLA</a></li><li class="chapter-item expanded "><a href="diffusion/backbone/transformer-unet.html"><strong aria-hidden="true">1.7.4.</strong> Transformer U-Net</a></li></ol></li><li class="chapter-item expanded "><a href="diffusion/guidance.html"><strong aria-hidden="true">1.8.</strong> Guidance</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion/guidance/classifier-guidance.html"><strong aria-hidden="true">1.8.1.</strong> ✅  Classifier Guidance</a></li><li class="chapter-item expanded "><a href="diffusion/guidance/classifier-free-guidance.html"><strong aria-hidden="true">1.8.2.</strong> ✅  Classifier-Free Guidance</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="diffusion_application.html"><strong aria-hidden="true">2.</strong> 扩散模型的应用</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion_application/image_generation.html"><strong aria-hidden="true">2.1.</strong> 扩散模型的应用: 图像生成</a></li><li class="chapter-item expanded "><a href="diffusion_application/video_generation.html"><strong aria-hidden="true">2.2.</strong> 扩散模型的应用: 视频生成</a></li><li class="chapter-item expanded "><a href="diffusion_application/audio_generation.html"><strong aria-hidden="true">2.3.</strong> 扩散模型的应用: 音频生成</a></li><li class="chapter-item expanded "><a href="diffusion_application/3d_generation.html"><strong aria-hidden="true">2.4.</strong> 扩散模型的应用: 3D 生成</a></li><li class="chapter-item expanded "><a href="diffusion_application/text_to_image_generation.html"><strong aria-hidden="true">2.5.</strong> 扩散模型的应用: 文本到图像生成</a></li><li class="chapter-item expanded "><a href="diffusion_application/text_to_video_generation.html"><strong aria-hidden="true">2.6.</strong> 扩散模型的应用: 文本到视频生成</a></li><li class="chapter-item expanded "><a href="diffusion_application/image_editing.html"><strong aria-hidden="true">2.7.</strong> 图像编辑</a></li></ol></li><li class="chapter-item expanded "><a href="normalizing-flow.html"><strong aria-hidden="true">3.</strong> 标准化流(Normalizing Flow)</a></li><li class="chapter-item expanded "><a href="vae.html"><strong aria-hidden="true">4.</strong> 变分自编码器 (VAE)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="vae/continuous.html"><strong aria-hidden="true">4.1.</strong> 连续变分自编码器</a></li><li class="chapter-item expanded "><a href="vae/vq-vae.html"><strong aria-hidden="true">4.2.</strong> 向量量化变分自编码器</a></li></ol></li><li class="chapter-item expanded "><a href="auto-regressive.html"><strong aria-hidden="true">5.</strong> 自回归模型(Auto-regressive Model)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="arm/pixel-rnn.html"><strong aria-hidden="true">5.1.</strong> PixelRNN</a></li><li class="chapter-item expanded "><a href="arm/chatgpt.html"><strong aria-hidden="true">5.2.</strong> ChatGPT</a></li></ol></li><li class="chapter-item expanded "><a href="agent.html"><strong aria-hidden="true">6.</strong> Agent</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="agent/agent_composition.html"><strong aria-hidden="true">6.1.</strong> Agent Composition</a></li></ol></li><li class="chapter-item expanded "><a href="discrete-state-model.html"><strong aria-hidden="true">7.</strong> Discrete-State Model</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="discrete-state-model/masked-discrete-state-model.html"><strong aria-hidden="true">7.1.</strong> Masked Discrete-State Model</a></li><li class="chapter-item expanded "><a href="discrete-state-model/uniform-discrete-state-model.html"><strong aria-hidden="true">7.2.</strong> Uniform Discrete-State Model</a></li></ol></li><li class="chapter-item expanded "><a href="multi-modal-model.html"><strong aria-hidden="true">8.</strong> 多模态模型(Multi-modal Model)</a></li><li class="chapter-item expanded "><a href="gan.html"><strong aria-hidden="true">9.</strong> 生成对抗网络 (GAN)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="gan/continuous.html"><strong aria-hidden="true">9.1.</strong> 连续生成对抗网络</a></li><li class="chapter-item expanded "><a href="gan/vq-gan.html"><strong aria-hidden="true">9.2.</strong> 向量量化生成对抗网络</a></li></ol></li><li class="chapter-item expanded "><a href="programming.html"><strong aria-hidden="true">10.</strong> 编程实践</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="programming/diffusion_model.html"><strong aria-hidden="true">10.1.</strong> Diffusion Model 的实现</a></li><li class="chapter-item expanded "><a href="programming/flow_matching.html"><strong aria-hidden="true">10.2.</strong> Flow Matching</a></li><li class="chapter-item expanded "><a href="programming/ddim.html"><strong aria-hidden="true">10.3.</strong> DDIM</a></li><li class="chapter-item expanded "><a href="programming/dpm.html"><strong aria-hidden="true">10.4.</strong> DPM</a></li><li class="chapter-item expanded "><a href="programming/flow_matching.html"><strong aria-hidden="true">10.5.</strong> Flow Matching</a></li><li class="chapter-item expanded "><a href="programming/stochastic-interpolants.html"><strong aria-hidden="true">10.6.</strong> Stochastic Interpolants</a></li><li class="chapter-item expanded "><a href="programming/pixel-rnn.html"><strong aria-hidden="true">10.7.</strong> PixelRNN</a></li><li class="chapter-item expanded "><a href="programming/chatgpt.html"><strong aria-hidden="true">10.8.</strong> ChatGPT</a></li><li class="chapter-item expanded "><a href="programming/agent_composition.html"><strong aria-hidden="true">10.9.</strong> Agent Composition</a></li><li class="chapter-item expanded "><a href="programming/masked-discrete-state-model.html"><strong aria-hidden="true">10.10.</strong> Masked Discrete-State Model</a></li><li class="chapter-item expanded "><a href="programming/multi-modal-model.html"><strong aria-hidden="true">10.11.</strong> Multi-modal Model</a></li><li class="chapter-item expanded "><a href="programming/gan.html"><strong aria-hidden="true">10.12.</strong> GAN</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Vincent教你学Generative AI (https://taohu.me/vincent-genai-course/) </h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="前言"><a class="header" href="#前言">前言</a></h1>
<p>欢迎阅读生成式AI模型指南。本教程为中国研究人员提供了一个全面的资源，以了解近年来革新人工智能领域的各种生成式AI模型。</p>
<h2 id="本教程的目的"><a class="header" href="#本教程的目的">本教程的目的</a></h2>
<p>本指南旨在提供对关键生成式AI模型的清晰而简明的概述，重点关注：</p>
<ul>
<li><strong>扩散模型</strong>：包括DDPM、Stable Diffusion和一致性模型</li>
<li><strong>标准化流</strong>：使用可逆变换的模型</li>
<li><strong>流匹配</strong>：基于连续时间流的生成模型</li>
<li><strong>变分自编码器(VAE)</strong>：具有概率编码器和解码器的潜变量模型</li>
<li><strong>生成对抗网络(GAN)</strong>：具有生成器和判别器网络的对抗框架</li>
<li><strong>自回归模型</strong>：如用于大型语言模型的Transformer架构</li>
</ul>
<p>每个部分都探讨了这些模型的理论基础、架构和实际应用，使不同技术专业水平的读者都能理解复杂的概念。</p>
<h2 id="如何使用本指南"><a class="header" href="#如何使用本指南">如何使用本指南</a></h2>
<p>本书的结构允许顺序阅读和针对特定模型的探索。您可以：</p>
<ol>
<li>按顺序阅读各章节，全面了解生成模型的全景</li>
<li>直接跳到您感兴趣的特定模型类型</li>
<li>使用参考部分查找原始论文和其他资源</li>
</ol>
<h2 id="贡献"><a class="header" href="#贡献">贡献</a></h2>
<p>教程源码: <a href="https://github.com/dongzhuoyao/vincent-genai-course">https://github.com/dongzhuoyao/vincent-genai-course</a></p>
<p>贡献请参考此框架: <a href="https://github.com/rust-lang/mdBook">https://github.com/rust-lang/mdBook</a></p>
<h2 id="许可证"><a class="header" href="#许可证">许可证</a></h2>
<p>本指南基于 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可证。</p>
<p>我们希望本指南能增强您对生成式AI的理解，并在这一激动人心的领域中启发您自己的实验和应用。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型"><a class="header" href="#扩散模型">扩散模型</a></h1>
<p>扩散模型是一类已经彻底改变了基于AI的内容创作的生成模型。这些模型通过逐渐向数据添加噪声，然后学习逆转这一过程来生成新样本。</p>
<h2 id="概述"><a class="header" href="#概述">概述</a></h2>
<p>扩散模型已成为生成式AI中最强大的方法之一，特别是对于图像，但也越来越多地应用于音频、视频和3D内容等其他模态。它们的工作原理是：</p>
<ol>
<li>前向过程：逐渐向数据添加噪声，直到变成纯噪声</li>
<li>反向过程：学习迭代去噪以生成新数据</li>
</ol>
<h2 id="主要优势"><a class="header" href="#主要优势">主要优势</a></h2>
<ul>
<li>高质量生成</li>
<li>灵活的条件机制</li>
<li>与GANs相比训练更稳定</li>
<li>强大的理论基础</li>
</ul>
<h2 id="扩散模型的类型"><a class="header" href="#扩散模型的类型">扩散模型的类型</a></h2>
<p>本节介绍扩散模型的几个重要变体：</p>
<ul>
<li><a href="./diffusion/vae.html">VAE</a>：变分自编码器的相关优化</li>
<li><a href="./diffusion/ddpm.html">DDPM</a>：原始的去噪扩散概率模型</li>
<li><a href="./diffusion/one-or-two-stage.html">Score-based Diffusion</a>：单阶段or两阶段扩散模型</li>
<li><a href="./diffusion/stable-diffusion.html">Stable Diffusion</a>：用于文本到图像生成的潜在扩散模型</li>
<li><a href="./diffusion/consistency.html">一致性模型</a>：快速采样扩散变体</li>
<li><a href="./diffusion/vector-quantized-diffusion.html">Vector Quantized Diffusion</a>：向量量化扩散模型</li>
</ul>
<p>每个子章节都提供了关于模型架构、训练过程和应用的详细解释。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="理论基础"><a class="header" href="#理论基础">理论基础</a></h1>
<ul>
<li><a href="diffusion//diffusion/basics_part/ddpm.html">DDPM</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="第一篇-diffusion-论文-sol-dickenstein"><a class="header" href="#第一篇-diffusion-论文-sol-dickenstein">第一篇 Diffusion 论文: Sol Dickenstein</a></h1>
<p>Sol Dickenstein et al. 2015, <a href="https://arxiv.org/abs/1503.03585">Diffusion Probabilistic Models</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ddpm"><a class="header" href="#ddpm">DDPM</a></h1>
<p>去噪扩散概率模型(DDPM)是一类通过逆转渐进噪声过程来学习生成数据的生成模型。</p>
<h2 id="关键概念"><a class="header" href="#关键概念">关键概念</a></h2>
<ul>
<li>前向扩散过程：逐渐向数据添加高斯噪声</li>
<li>反向扩散过程：学习逐步对图像去噪</li>
<li>U-Net架构：常用作去噪网络</li>
</ul>
<h2 id="数学公式"><a class="header" href="#数学公式">数学公式</a></h2>
<p>DDPM通过定义一个逐渐向数据添加噪声直至变成纯噪声的前向扩散过程，然后训练模型来逆转这一过程。</p>
<h2 id="参考文献"><a class="header" href="#参考文献">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2006.11239">Ho et al. (2020), "去噪扩散概率模型"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="score-matching"><a class="header" href="#score-matching">Score Matching</a></h1>
<p>Yang Song, 2019, <a href="https://arxiv.org/abs/2011.13456">Score-Based Generative Modeling through Stochastic Differential Equations</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="score-based-diffusion"><a class="header" href="#score-based-diffusion">Score-based Diffusion</a></h1>
<p>Yang Song, ICLR 2021, <a href="https://arxiv.org/abs/2011.13456">Score-based Generative Modeling through Stochastic Differential Equations</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="flow-matching"><a class="header" href="#flow-matching">Flow Matching</a></h1>
<p>Flow Matching is a generative modeling technique that builds upon the ideas of continuous normalizing flows and probability flow ODEs, offering an alternative training approach for generative models.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Flow Matching defines a continuous-time transformation from a simple distribution (like a Gaussian) to a complex target distribution. Unlike traditional normalizing flows, flow matching doesn't require computing the Jacobian determinant, making it more flexible and computationally efficient.</p>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<ul>
<li><strong>Vector Fields</strong>: Learning a vector field to represent the continuous-time flow</li>
<li><strong>Straight-line Paths</strong>: Using simple paths between distributions</li>
<li><strong>Conditional Flow Matching</strong>: Extending to conditional generation</li>
<li><strong>ODE-based Generation</strong>: Sampling by solving an ordinary differential equation</li>
</ul>
<h2 id="relation-to-other-models"><a class="header" href="#relation-to-other-models">Relation to Other Models</a></h2>
<ul>
<li><strong>Diffusion Models</strong>: Flow matching can be seen as a generalization of score-based diffusion models</li>
<li><strong>Normalizing Flows</strong>: Similar concept but with different training objectives</li>
<li><strong>Optimal Transport</strong>: Connection to optimal transport theory</li>
</ul>
<h2 id="advantages"><a class="header" href="#advantages">Advantages</a></h2>
<ul>
<li><strong>Flexible Architecture</strong>: No invertibility requirement</li>
<li><strong>Efficient Training</strong>: More efficient than score matching in some cases</li>
<li><strong>Theoretical Guarantees</strong>: Well-founded mathematical framework</li>
<li><strong>Stable Training</strong>: Often more stable than adversarial approaches</li>
</ul>
<h2 id="applications"><a class="header" href="#applications">Applications</a></h2>
<ul>
<li><strong>Image Generation</strong>: Creating realistic images</li>
<li><strong>Shape Generation</strong>: 3D shape synthesis</li>
<li><strong>Audio Synthesis</strong>: Generating audio waveforms</li>
<li><strong>Density Estimation</strong>: Learning complex distributions</li>
</ul>
<h2 id="awesome-flow-matching"><a class="header" href="#awesome-flow-matching">Awesome Flow Matching</a></h2>
<ul>
<li><a href="https://github.com/dongzhuoyao/awesome-flow-matching">https://github.com/dongzhuoyao/awesome-flow-matching</a></li>
</ul>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2210.02747">Lipman et al. (2022), "Flow Matching for Generative Modeling"</a></li>
<li><a href="https://arxiv.org/abs/2209.03003">Liu et al. (2022), "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow"</a></li>
<li><a href="https://arxiv.org/abs/2302.00482">Tong et al. (2023), "Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stochastic-interpolants"><a class="header" href="#stochastic-interpolants">Stochastic Interpolants</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="采样方法"><a class="header" href="#采样方法">采样方法</a></h1>
<p>默认ancestral sampling</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ode-采样方法"><a class="header" href="#ode-采样方法">ODE 采样方法</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ddim"><a class="header" href="#ddim">DDIM</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dpm"><a class="header" href="#dpm">DPM</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vae-相关的优化"><a class="header" href="#vae-相关的优化">VAE 相关的优化</a></h1>
<h2 id="vae-由三部分组成"><a class="header" href="#vae-由三部分组成">VAE 由三部分组成</a></h2>
<h2 id="vae-的优化-scale--equivariance"><a class="header" href="#vae-的优化-scale--equivariance">VAE 的优化: Scale  Equivariance</a></h2>
<p><a href="https://www.bilibili.com/video/BV1FRotYFEEv/?vd_source=b59aa3b60dba6772a351323e882c4253">关于SD VAE一个简单到令人发指的Trick</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stable-diffusion-稳定扩散模型"><a class="header" href="#stable-diffusion-稳定扩散模型">Stable Diffusion 稳定扩散模型</a></h1>
<p>Stable Diffusion是由Stability AI开发的潜在扩散模型，能够根据文本描述生成详细的图像。</p>
<h2 id="架构"><a class="header" href="#架构">架构</a></h2>
<ul>
<li>潜在空间扩散：在压缩的潜在空间中应用扩散过程</li>
<li>文本条件：使用CLIP文本嵌入来引导生成过程</li>
<li>VAE：将图像编码到潜在空间并解码回来</li>
<li>UNet：在潜在空间中执行去噪过程</li>
</ul>
<h2 id="主要特点"><a class="header" href="#主要特点">主要特点</a></h2>
<ul>
<li>文本到图像生成</li>
<li>图像到图像转换</li>
<li>图像修复和扩展</li>
<li>微调能力</li>
</ul>
<h2 id="应用"><a class="header" href="#应用">应用</a></h2>
<ul>
<li>创意艺术生成</li>
<li>设计原型制作</li>
<li>内容创作</li>
<li>图像编辑</li>
</ul>
<h2 id="参考文献-1"><a class="header" href="#参考文献-1">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2112.10752">Rombach et al. (2022), "使用潜在扩散模型进行高分辨率图像合成"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="一致性模型"><a class="header" href="#一致性模型">一致性模型</a></h1>
<p>一致性模型是一种生成模型，相比传统扩散模型提供更快的采样速度，同时保持生成质量。</p>
<h2 id="关键创新"><a class="header" href="#关键创新">关键创新</a></h2>
<ul>
<li>单步生成：仅需一步即可生成高质量样本</li>
<li>少步生成：通过少量采样步骤提供质量-速度的权衡</li>
<li>蒸馏方法：从预训练的扩散模型中蒸馏知识</li>
</ul>
<h2 id="优势"><a class="header" href="#优势">优势</a></h2>
<ul>
<li>比常规扩散模型采样速度快得多</li>
<li>确定性采样过程</li>
<li>保持与扩散模型相当的生成质量</li>
</ul>
<h2 id="技术细节"><a class="header" href="#技术细节">技术细节</a></h2>
<ul>
<li>一致性函数：将噪声映射到数据点</li>
<li>一致性蒸馏：学习一致性函数的训练技术</li>
<li>自我条件化：提高生成质量</li>
</ul>
<h2 id="参考文献-2"><a class="header" href="#参考文献-2">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2303.01469">Song et al. (2023), "一致性模型"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="improved-consistency-models"><a class="header" href="#improved-consistency-models">improved consistency models</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="simplified-consistency-models"><a class="header" href="#simplified-consistency-models">Simplified Consistency Models</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="shorcut-models"><a class="header" href="#shorcut-models">Shorcut Models</a></h1>
<p>B 站链接<a href="https://www.bilibili.com/video/BV113Z7YrEHs/">https://www.bilibili.com/video/BV113Z7YrEHs/</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型骨干网络设计"><a class="header" href="#扩散模型骨干网络设计">扩散模型骨干网络设计</a></h1>
<p>扩散模型的性能在很大程度上取决于其骨干网络的设计。这些骨干网络负责学习噪声预测或去噪过程，对生成质量至关重要。</p>
<h2 id="u-net架构"><a class="header" href="#u-net架构">U-Net架构</a></h2>
<p>U-Net是扩散模型中最常用的骨干网络，其特点包括：</p>
<ul>
<li><strong>对称编码器-解码器结构</strong>：通过下采样逐步减小特征图尺寸，然后通过上采样恢复尺寸</li>
<li><strong>跳跃连接</strong>：连接编码器和解码器对应层，保留细节信息</li>
<li><strong>残差块</strong>：改进的ResNet块，提高训练稳定性和模型性能</li>
<li><strong>自注意力层</strong>：在某些分辨率层中引入，捕获远程依赖关系</li>
</ul>
<h2 id="mamba架构"><a class="header" href="#mamba架构">Mamba架构</a></h2>
<p>Mamba是一种基于RNN的骨干网络，其特点包括：</p>
<ul>
<li><strong>时间步嵌入</strong>：将去噪步骤转换为特征表示，通常使用正弦位置编码</li>
<li><strong>条件嵌入</strong>：</li>
</ul>
<h2 id="其他常见骨干网络"><a class="header" href="#其他常见骨干网络">其他常见骨干网络</a></h2>
<h3 id="transformer架构"><a class="header" href="#transformer架构">Transformer架构</a></h3>
<ul>
<li><strong>Diffusion Transformer (DiT)</strong>：使用Transformer块替代卷积层</li>
<li><strong>U-ViT</strong>：结合U-Net的多尺度特性和Vision Transformer的注意力机制</li>
<li><strong>优势</strong>：更好地捕获全局依赖关系，对大尺寸图像效果更佳</li>
</ul>
<h3 id="高效改进"><a class="header" href="#高效改进">高效改进</a></h3>
<ul>
<li><strong>Progressive U-Net</strong>：渐进式的U-Net变体，针对不同噪声级别使用不同复杂度的网络</li>
<li><strong>轻量级设计</strong>：使用分组卷积、深度可分离卷积等减少参数量</li>
<li><strong>知识蒸馏</strong>：从大型模型蒸馏知识到小型模型，平衡效率和质量</li>
</ul>
<h2 id="时间步和条件嵌入"><a class="header" href="#时间步和条件嵌入">时间步和条件嵌入</a></h2>
<ul>
<li><strong>时间步嵌入</strong>：将去噪步骤转换为特征表示，通常使用正弦位置编码</li>
<li><strong>条件嵌入</strong>：
<ul>
<li><strong>类别条件</strong>：使用类别嵌入或one-hot向量</li>
<li><strong>文本条件</strong>：使用CLIP或T5等语言模型的文本编码</li>
<li><strong>跨模态条件</strong>：结合多种模态输入的特征</li>
</ul>
</li>
</ul>
<h2 id="扩散模型骨干设计中的关键考虑因素"><a class="header" href="#扩散模型骨干设计中的关键考虑因素">扩散模型骨干设计中的关键考虑因素</a></h2>
<ol>
<li><strong>感受野大小</strong>：更大的感受野有助于捕获全局结构</li>
<li><strong>参数效率</strong>：优化参数数量和计算复杂度</li>
<li><strong>多分辨率处理</strong>：有效处理不同尺度的特征</li>
<li><strong>注意力机制</strong>：在合适的层级高效应用注意力机制</li>
<li><strong>可扩展性</strong>：能够适应不同尺寸的输入和复杂度要求</li>
</ol>
<h2 id="最新研究方向"><a class="header" href="#最新研究方向">最新研究方向</a></h2>
<ul>
<li><strong>动态架构</strong>：根据噪声水平动态调整网络结构</li>
<li><strong>混合架构</strong>：结合CNN和Transformer的优点</li>
<li><strong>一致性架构</strong>：专为一致性模型设计的特殊骨干网络</li>
<li><strong>量化感知设计</strong>：考虑到部署时量化需求的骨干网络设计</li>
</ul>
<h2 id="参考文献-3"><a class="header" href="#参考文献-3">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1505.04597">Ronneberger et al. (2015), "U-Net: 用于生物医学图像分割的卷积网络"</a></li>
<li><a href="https://arxiv.org/abs/2006.11239">Ho et al. (2020), "去噪扩散概率模型"</a></li>
<li><a href="https://arxiv.org/abs/2212.09748">Peebles &amp; Xie (2023), "扩散变换器"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transformer"><a class="header" href="#transformer">Transformer</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="u-net"><a class="header" href="#u-net">U-Net</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mamba"><a class="header" href="#mamba">Mamba</a></h1>
<p>Mamba 是一种基于状态空间模型（SSM）的新型序列建模架构，它通过选择性状态空间机制来高效处理长序列数据。相比传统的 Transformer，Mamba 在保持性能的同时显著降低了计算复杂度。</p>
<h2 id="架构-1"><a class="header" href="#架构-1">架构</a></h2>
<p>Mamba 的主要组件包括：</p>
<ol>
<li>
<p><strong>选择性状态空间层</strong></p>
<ul>
<li>状态空间模型：捕获序列依赖关系</li>
<li>选择性机制：动态调整状态转换</li>
<li>并行计算：支持高效的序列处理</li>
</ul>
</li>
<li>
<p><strong>多层堆叠</strong></p>
<ul>
<li>残差连接：促进梯度流动</li>
<li>层归一化：稳定训练过程</li>
<li>前馈网络：非线性变换</li>
</ul>
</li>
<li>
<p><strong>输入投影</strong></p>
<ul>
<li>线性投影：调整特征维度</li>
<li>位置编码：提供序列位置信息</li>
</ul>
</li>
</ol>
<h2 id="数学框架"><a class="header" href="#数学框架">数学框架</a></h2>
<h3 id="状态空间模型"><a class="header" href="#状态空间模型">状态空间模型</a></h3>
<p>Mamba 使用连续时间状态空间模型：</p>
<p>[ \frac{d}{dt}h(t) = Ah(t) + Bx(t) ]
[ y(t) = Ch(t) + Dx(t) ]</p>
<p>其中：</p>
<ul>
<li>( h(t) ) 是隐藏状态</li>
<li>( x(t) ) 是输入</li>
<li>( y(t) ) 是输出</li>
<li>A, B, C, D 是系统参数</li>
</ul>
<h3 id="离散化"><a class="header" href="#离散化">离散化</a></h3>
<p>通过零阶保持（ZOH）将连续系统离散化：</p>
<p>[ h_{k+1} = (I + \Delta A)h_k + \Delta Bx_k ]
[ y_k = Ch_k + Dx_k ]</p>
<h2 id="变体"><a class="header" href="#变体">变体</a></h2>
<h3 id="mamba-2"><a class="header" href="#mamba-2">Mamba-2</a></h3>
<p>通过改进选择性机制和状态空间设计来增强性能。</p>
<h3 id="多模态-mamba"><a class="header" href="#多模态-mamba">多模态 Mamba</a></h3>
<p>扩展支持多模态输入的处理能力。</p>
<h2 id="优势-1"><a class="header" href="#优势-1">优势</a></h2>
<ol>
<li><strong>计算效率</strong>：线性时间复杂度的序列处理</li>
<li><strong>长程依赖</strong>：有效捕获长序列依赖关系</li>
<li><strong>并行计算</strong>：支持高效的并行处理</li>
<li><strong>内存效率</strong>：较低的内存占用</li>
</ol>
<h2 id="局限性"><a class="header" href="#局限性">局限性</a></h2>
<ol>
<li><strong>状态空间设计</strong>：需要仔细设计状态空间参数</li>
<li><strong>训练稳定性</strong>：可能需要特殊的训练策略</li>
<li><strong>实现复杂度</strong>：实现相对复杂</li>
</ol>
<h2 id="应用-1"><a class="header" href="#应用-1">应用</a></h2>
<ol>
<li><strong>序列建模</strong>：长文本处理</li>
<li><strong>时间序列预测</strong>：预测任务</li>
<li><strong>音频处理</strong>：音频序列处理</li>
<li><strong>基因组学</strong>：DNA 序列分析</li>
</ol>
<h2 id="参考文献-4"><a class="header" href="#参考文献-4">参考文献</a></h2>
<ol>
<li>Gu, A., &amp; Dao, T. (2023). Mamba: Linear-time sequence modeling with selective state spaces.</li>
<li>Gu, A., et al. (2022). Efficiently modeling long sequences with structured state spaces.</li>
<li>Smith, J. T., et al. (2023). Simplified state space layers for sequence modeling.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transformer-u-net"><a class="header" href="#transformer-u-net">Transformer U-Net</a></h1>
<p>Transformer U-Net 是一种结合了 Transformer 和 U-Net 架构的骨干网络，它通过自注意力机制和跳跃连接来增强特征提取和重建能力。这种架构特别适合处理需要捕获全局和局部信息的任务。</p>
<h2 id="架构-2"><a class="header" href="#架构-2">架构</a></h2>
<p>Transformer U-Net 的主要组件包括：</p>
<ol>
<li>
<p><strong>编码器路径</strong></p>
<ul>
<li>卷积层：进行下采样和特征提取</li>
<li>Transformer 块：捕获全局依赖关系</li>
<li>位置编码：提供序列位置信息</li>
</ul>
</li>
<li>
<p><strong>解码器路径</strong></p>
<ul>
<li>反卷积层：进行上采样和特征重建</li>
<li>Transformer 块：处理全局上下文</li>
<li>跳跃连接：融合不同尺度的特征</li>
</ul>
</li>
<li>
<p><strong>瓶颈层</strong></p>
<ul>
<li>Transformer 块：处理最深层特征</li>
<li>全局上下文：捕获整体信息</li>
</ul>
</li>
</ol>
<h2 id="数学框架-1"><a class="header" href="#数学框架-1">数学框架</a></h2>
<h3 id="自注意力机制"><a class="header" href="#自注意力机制">自注意力机制</a></h3>
<p>Transformer 块中的自注意力计算：</p>
<p>[ \text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V ]</p>
<p>其中：</p>
<ul>
<li>Q, K, V 分别是查询、键和值矩阵</li>
<li>( d_k ) 是键向量的维度</li>
</ul>
<h3 id="位置编码"><a class="header" href="#位置编码">位置编码</a></h3>
<p>使用正弦和余弦函数的位置编码：</p>
<p>[ PE_{(pos,2i)} = \sin(pos/10000^{2i/d_{\text{model}}}) ]
[ PE_{(pos,2i+1)} = \cos(pos/10000^{2i/d_{\text{model}}}) ]</p>
<h2 id="变体-1"><a class="header" href="#变体-1">变体</a></h2>
<h3 id="多尺度-transformer-u-net"><a class="header" href="#多尺度-transformer-u-net">多尺度 Transformer U-Net</a></h3>
<p>通过引入多尺度特征处理和注意力机制来增强性能。</p>
<h3 id="轻量级-transformer-u-net"><a class="header" href="#轻量级-transformer-u-net">轻量级 Transformer U-Net</a></h3>
<p>通过减少参数和计算量来优化效率。</p>
<h2 id="优势-2"><a class="header" href="#优势-2">优势</a></h2>
<ol>
<li><strong>全局感知</strong>：通过自注意力机制捕获全局依赖</li>
<li><strong>多尺度处理</strong>：结合 U-Net 的跳跃连接处理不同尺度</li>
<li><strong>灵活架构</strong>：可以根据任务需求调整 Transformer 块数量</li>
<li><strong>并行计算</strong>：支持高效的并行处理</li>
</ol>
<h2 id="局限性-1"><a class="header" href="#局限性-1">局限性</a></h2>
<ol>
<li><strong>计算复杂度</strong>：自注意力机制的计算开销较大</li>
<li><strong>内存需求</strong>：需要较大的内存来存储注意力图</li>
<li><strong>训练难度</strong>：需要仔细调整学习率和优化器</li>
</ol>
<h2 id="应用-2"><a class="header" href="#应用-2">应用</a></h2>
<ol>
<li><strong>图像生成</strong>：高质量图像生成</li>
<li><strong>图像分割</strong>：精确的图像分割</li>
<li><strong>医学图像处理</strong>：医学图像分析和处理</li>
<li><strong>视频处理</strong>：视频帧生成和处理</li>
</ol>
<h2 id="参考文献-5"><a class="header" href="#参考文献-5">参考文献</a></h2>
<ol>
<li>Chen, J., et al. (2021). TransUNet: Transformers make strong encoders for medical image segmentation.</li>
<li>Wang, W., et al. (2021). Pyramid vision transformer: A versatile backbone for dense prediction without convolutions.</li>
<li>Liu, Z., et al. (2021). Swin transformer: Hierarchical vision transformer using shifted windows.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="guidance"><a class="header" href="#guidance">Guidance</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="classifier-guidance"><a class="header" href="#classifier-guidance">Classifier Guidance</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="classifier-free-guidance"><a class="header" href="#classifier-free-guidance">Classifier-Free Guidance</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型的应用"><a class="header" href="#扩散模型的应用">扩散模型的应用</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型的应用-图像生成"><a class="header" href="#扩散模型的应用-图像生成">扩散模型的应用: 图像生成</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型的应用-视频生成"><a class="header" href="#扩散模型的应用-视频生成">扩散模型的应用: 视频生成</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型的应用-音频生成"><a class="header" href="#扩散模型的应用-音频生成">扩散模型的应用: 音频生成</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型的应用-3d-生成"><a class="header" href="#扩散模型的应用-3d-生成">扩散模型的应用: 3D 生成</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型的应用-文本到图像生成"><a class="header" href="#扩散模型的应用-文本到图像生成">扩散模型的应用: 文本到图像生成</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型的应用-文本到视频生成"><a class="header" href="#扩散模型的应用-文本到视频生成">扩散模型的应用: 文本到视频生成</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="图像编辑"><a class="header" href="#图像编辑">图像编辑</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="normalizing-flow"><a class="header" href="#normalizing-flow">Normalizing Flow</a></h1>
<p>Normalizing Flows are a family of generative models that use invertible transformations to map between a simple base distribution and a complex target distribution.</p>
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<ul>
<li><strong>Invertible Transformations</strong>: Bijective mappings between spaces</li>
<li><strong>Change of Variables Formula</strong>: Mathematical foundation that allows exact likelihood computation</li>
<li><strong>Flow-based Generation</strong>: Sampling from a simple distribution and transforming through learned flows</li>
</ul>
<h2 id="types-of-normalizing-flows"><a class="header" href="#types-of-normalizing-flows">Types of Normalizing Flows</a></h2>
<ul>
<li><strong>NICE/RealNVP</strong>: Coupling layers with affine transformations</li>
<li><strong>Glow</strong>: Extended RealNVP with 1x1 convolutions</li>
<li><strong>Autoregressive Flows (IAF, MAF)</strong>: Using autoregressive transformations</li>
<li><strong>Continuous Normalizing Flows</strong>: Defining flows using ordinary differential equations</li>
</ul>
<h2 id="advantages-1"><a class="header" href="#advantages-1">Advantages</a></h2>
<ul>
<li><strong>Exact Likelihood</strong>: Unlike VAEs, flows provide exact likelihood computation</li>
<li><strong>Efficient Sampling</strong>: Unlike autoregressive models, sampling can be parallelized</li>
<li><strong>Invertibility</strong>: Can transform in both directions (generation and inference)</li>
<li><strong>Stable Training</strong>: More stable than GANs, using maximum likelihood</li>
</ul>
<h2 id="applications-1"><a class="header" href="#applications-1">Applications</a></h2>
<ul>
<li><strong>Image Generation</strong>: High-quality image synthesis</li>
<li><strong>Anomaly Detection</strong>: Identifying outliers in data</li>
<li><strong>Density Estimation</strong>: Learning complex probability distributions</li>
<li><strong>Variational Inference</strong>: More expressive posterior approximations</li>
</ul>
<h2 id="challenges"><a class="header" href="#challenges">Challenges</a></h2>
<ul>
<li><strong>Architectural Constraints</strong>: Requiring invertibility limits model expressiveness</li>
<li><strong>Computational Cost</strong>: Some flows can be computationally expensive</li>
<li><strong>High-dimensional Data</strong>: Scaling to very high dimensions can be challenging</li>
</ul>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1505.05770">Rezende &amp; Mohamed (2015), "Variational Inference with Normalizing Flows"</a></li>
<li><a href="https://arxiv.org/abs/1605.08803">Dinh et al. (2016), "Density estimation using Real NVP"</a></li>
<li><a href="https://arxiv.org/abs/1807.03039">Kingma &amp; Dhariwal (2018), "Glow: Generative Flow with Invertible 1x1 Convolutions"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="变分自编码器-vae"><a class="header" href="#变分自编码器-vae">变分自编码器 (VAE)</a></h1>
<p>变分自编码器（VAE）是一类重要的生成模型，它通过结合神经网络和变分推断来学习数据的潜在表示。VAE 的核心思想是通过编码器将输入数据映射到潜在空间，然后通过解码器从潜在空间重建数据。</p>
<h2 id="主要类型"><a class="header" href="#主要类型">主要类型</a></h2>
<h3 id="连续变分自编码器"><a class="header" href="#连续变分自编码器">连续变分自编码器</a></h3>
<p>连续 VAE 使用连续的潜在空间，通过重参数化技巧实现端到端的训练。它特别适合处理连续数据，如自然图像。</p>
<p><a href="./vae/continuous.html">了解更多关于连续变分自编码器</a></p>
<h3 id="向量量化变分自编码器-vq-vae"><a class="header" href="#向量量化变分自编码器-vq-vae">向量量化变分自编码器 (VQ-VAE)</a></h3>
<p>VQ-VAE 使用离散的潜在表示，通过向量量化将连续向量映射到离散的码本。它特别适合处理离散数据，如文本和音频。</p>
<p><a href="./vae/vq-vae.html">了解更多关于向量量化变分自编码器</a></p>
<h2 id="应用领域"><a class="header" href="#应用领域">应用领域</a></h2>
<ol>
<li>
<p><strong>图像生成与处理</strong></p>
<ul>
<li>图像压缩</li>
<li>图像重建</li>
<li>风格迁移</li>
</ul>
</li>
<li>
<p><strong>音频处理</strong></p>
<ul>
<li>语音合成</li>
<li>音频压缩</li>
<li>音乐生成</li>
</ul>
</li>
<li>
<p><strong>文本生成</strong></p>
<ul>
<li>文本压缩</li>
<li>文本生成</li>
<li>文本表示学习</li>
</ul>
</li>
<li>
<p><strong>异常检测</strong></p>
<ul>
<li>基于重构误差的异常检测</li>
<li>数据清洗</li>
</ul>
</li>
</ol>
<h2 id="发展趋势"><a class="header" href="#发展趋势">发展趋势</a></h2>
<ol>
<li>
<p><strong>架构改进</strong></p>
<ul>
<li>更高效的编码器-解码器结构</li>
<li>更好的潜在空间组织</li>
<li>更强的生成能力</li>
</ul>
</li>
<li>
<p><strong>训练方法</strong></p>
<ul>
<li>更稳定的训练策略</li>
<li>更好的损失函数设计</li>
<li>更高效的优化方法</li>
</ul>
</li>
<li>
<p><strong>应用扩展</strong></p>
<ul>
<li>多模态学习</li>
<li>跨域迁移</li>
<li>可解释性研究</li>
</ul>
</li>
</ol>
<h2 id="参考文献-6"><a class="header" href="#参考文献-6">参考文献</a></h2>
<ol>
<li>Kingma, D. P., &amp; Welling, M. (2013). Auto-encoding variational bayes.</li>
<li>van den Oord, A., et al. (2017). Neural discrete representation learning.</li>
<li>Razavi, A., et al. (2019). Generating diverse high-fidelity images with VQ-VAE-2.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="连续变分自编码器-continuous-vae"><a class="header" href="#连续变分自编码器-continuous-vae">连续变分自编码器 (Continuous VAE)</a></h1>
<p>变分自编码器（VAE）是一种生成模型，它结合了神经网络和变分推断来学习数据的潜在表示。VAE 的核心思想是通过编码器将输入数据映射到潜在空间，然后通过解码器从潜在空间重建数据。</p>
<h2 id="架构-3"><a class="header" href="#架构-3">架构</a></h2>
<p>VAE 由两个主要部分组成：</p>
<ol>
<li><strong>编码器网络</strong>：将输入数据映射到潜在空间的分布参数（均值和方差）</li>
<li><strong>解码器网络</strong>：将潜在空间的样本映射回数据空间</li>
</ol>
<h2 id="数学框架-2"><a class="header" href="#数学框架-2">数学框架</a></h2>
<h3 id="变分推断"><a class="header" href="#变分推断">变分推断</a></h3>
<p>VAE 使用变分推断来优化以下目标函数（证据下界，ELBO）：</p>
<p>[ \mathcal{L}<em>{\text{VAE}} = \mathbb{E}</em>{q_\phi(z|x)}[\log p_\theta(x|z)] - \text{KL}(q_\phi(z|x) | p(z)) ]</p>
<p>其中：</p>
<ul>
<li>( q_\phi(z|x) ) 是编码器定义的近似后验分布</li>
<li>( p_\theta(x|z) ) 是解码器定义的似然函数</li>
<li>( p(z) ) 是先验分布（通常为标准正态分布）</li>
<li>KL 项是 KL 散度，用于正则化潜在空间</li>
</ul>
<h3 id="重参数化技巧"><a class="header" href="#重参数化技巧">重参数化技巧</a></h3>
<p>为了能够通过编码器反向传播，VAE 使用重参数化技巧：</p>
<p>[ z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I) ]</p>
<h2 id="变体-2"><a class="header" href="#变体-2">变体</a></h2>
<h3 id="β-vae"><a class="header" href="#β-vae">β-VAE</a></h3>
<p>β-VAE 通过引入权重系数 β 来增强潜在空间的结构化表示：</p>
<p>[ \mathcal{L}<em>{\beta\text{-VAE}} = \mathbb{E}</em>{q_\phi(z|x)}[\log p_\theta(x|z)] - \beta \text{KL}(q_\phi(z|x) | p(z)) ]</p>
<h3 id="条件-vae-cvae"><a class="header" href="#条件-vae-cvae">条件 VAE (CVAE)</a></h3>
<p>CVAE 通过引入条件信息来增强生成过程：</p>
<p>[ \mathcal{L}<em>{\text{CVAE}} = \mathbb{E}</em>{q_\phi(z|x,c)}[\log p_\theta(x|z,c)] - \text{KL}(q_\phi(z|x,c) | p(z|c)) ]</p>
<h2 id="优势-3"><a class="header" href="#优势-3">优势</a></h2>
<ol>
<li><strong>结构化潜在空间</strong>：通过 KL 散度正则化，VAE 学习到结构化的潜在表示</li>
<li><strong>生成能力</strong>：可以从潜在空间采样生成新的数据样本</li>
<li><strong>无监督学习</strong>：不需要标签数据就能学习数据的表示</li>
<li><strong>概率框架</strong>：提供了完整的概率模型框架</li>
</ol>
<h2 id="局限性-2"><a class="header" href="#局限性-2">局限性</a></h2>
<ol>
<li><strong>模糊输出</strong>：由于 KL 散度正则化，生成的结果可能过于平滑</li>
<li><strong>后验崩塌</strong>：编码器可能忽略输入信息，导致 KL 项接近零</li>
<li><strong>近似差距</strong>：变分推断的近似可能导致次优解</li>
</ol>
<h2 id="应用-3"><a class="header" href="#应用-3">应用</a></h2>
<ol>
<li><strong>图像生成</strong>：生成新的图像样本</li>
<li><strong>表示学习</strong>：学习数据的低维表示</li>
<li><strong>异常检测</strong>：基于重构误差检测异常样本</li>
<li><strong>数据压缩</strong>：通过潜在表示压缩数据</li>
</ol>
<h2 id="参考文献-7"><a class="header" href="#参考文献-7">参考文献</a></h2>
<ol>
<li>Kingma, D. P., &amp; Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.</li>
<li>Higgins, I., et al. (2017). beta-VAE: Learning basic visual concepts with a constrained variational framework.</li>
<li>Sohn, K., et al. (2015). Learning structured output representation using deep conditional generative models.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="向量量化变分自编码器-vq-vae-1"><a class="header" href="#向量量化变分自编码器-vq-vae-1">向量量化变分自编码器 (VQ-VAE)</a></h1>
<p>向量量化变分自编码器（VQ-VAE）是 VAE 的一个重要变体，它使用离散的潜在表示而不是连续的潜在空间。VQ-VAE 通过将连续向量映射到离散的码本（codebook）来实现这一点，这使得它特别适合处理离散数据（如文本、音频等）和需要精确重建的场景。</p>
<h2 id="架构-4"><a class="header" href="#架构-4">架构</a></h2>
<p>VQ-VAE 的主要组件包括：</p>
<ol>
<li><strong>编码器网络</strong>：将输入数据映射到连续向量空间</li>
<li><strong>向量量化层</strong>：将连续向量映射到最近的码本条目</li>
<li><strong>解码器网络</strong>：从量化后的向量重建输入数据</li>
<li><strong>码本</strong>：包含 K 个可学习的向量，用于量化</li>
</ol>
<h2 id="数学框架-3"><a class="header" href="#数学框架-3">数学框架</a></h2>
<h3 id="向量量化过程"><a class="header" href="#向量量化过程">向量量化过程</a></h3>
<p>给定编码器输出 ( z_e(x) )，VQ-VAE 通过以下步骤进行量化：</p>
<ol>
<li>计算与码本中所有向量的距离</li>
<li>选择最近的码本条目</li>
<li>使用选中的码本条目进行重建</li>
</ol>
<p>量化过程可以表示为：</p>
<p>[ z_q(x) = \text{VQ}(z_e(x)) = e_k, \quad k = \arg\min_j |z_e(x) - e_j|_2 ]</p>
<h3 id="训练目标"><a class="header" href="#训练目标">训练目标</a></h3>
<p>VQ-VAE 的训练目标包括：</p>
<ol>
<li><strong>重建损失</strong>：确保解码器能够准确重建输入</li>
<li><strong>码本损失</strong>：更新码本向量以更好地表示输入</li>
<li><strong>承诺损失</strong>：防止编码器输出在码本条目之间频繁切换</li>
</ol>
<p>总损失函数为：</p>
<p>[ \mathcal{L}<em>{\text{VQ-VAE}} = \mathcal{L}</em>{\text{recon}} + |\text{sg}[z_e(x)] - e_k|_2^2 + |\text{sg}[e_k] - z_e(x)|_2^2 ]</p>
<p>其中 (\text{sg}) 表示停止梯度操作。</p>
<h2 id="变体-3"><a class="header" href="#变体-3">变体</a></h2>
<h3 id="vq-vae-2"><a class="header" href="#vq-vae-2">VQ-VAE-2</a></h3>
<p>VQ-VAE-2 通过引入分层结构来增强生成能力，使用多个 VQ 层处理不同尺度的特征。</p>
<h3 id="vq-gan"><a class="header" href="#vq-gan">VQ-GAN</a></h3>
<p>VQ-GAN 将 VQ-VAE 与对抗训练相结合，通过判别器来提升生成质量。</p>
<h2 id="优势-4"><a class="header" href="#优势-4">优势</a></h2>
<ol>
<li><strong>离散表示</strong>：更适合处理离散数据</li>
<li><strong>精确重建</strong>：可以产生更清晰的输出</li>
<li><strong>自回归生成</strong>：支持自回归式的生成过程</li>
<li><strong>多尺度处理</strong>：可以处理不同尺度的特征</li>
</ol>
<h2 id="局限性-3"><a class="header" href="#局限性-3">局限性</a></h2>
<ol>
<li><strong>码本大小限制</strong>：码本大小需要预先设定</li>
<li><strong>计算开销</strong>：量化过程需要计算与所有码本条目的距离</li>
<li><strong>训练稳定性</strong>：需要仔细平衡各个损失项</li>
</ol>
<h2 id="应用-4"><a class="header" href="#应用-4">应用</a></h2>
<ol>
<li><strong>图像生成</strong>：高质量图像生成</li>
<li><strong>音频处理</strong>：语音合成和音频压缩</li>
<li><strong>文本生成</strong>：基于离散 token 的文本生成</li>
<li><strong>视频生成</strong>：多帧视频生成</li>
</ol>
<h2 id="参考文献-8"><a class="header" href="#参考文献-8">参考文献</a></h2>
<ol>
<li>van den Oord, A., et al. (2017). Neural discrete representation learning.</li>
<li>Razavi, A., et al. (2019). Generating diverse high-fidelity images with VQ-VAE-2.</li>
<li>Esser, P., et al. (2021). Taming transformers for high-resolution image synthesis.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="auto-regressive-model"><a class="header" href="#auto-regressive-model">Auto-regressive Model</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pixelrnn"><a class="header" href="#pixelrnn">PixelRNN</a></h1>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="agent"><a class="header" href="#agent">Agent</a></h1>
<h2 id="什么是agent"><a class="header" href="#什么是agent">什么是Agent</a></h2>
<h2 id="如何构建一个agent"><a class="header" href="#如何构建一个agent">如何构建一个Agent</a></h2>
<h2 id="如何使用agent"><a class="header" href="#如何使用agent">如何使用Agent</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="agent-composition"><a class="header" href="#agent-composition">Agent Composition</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="discrete-state-model"><a class="header" href="#discrete-state-model">Discrete-State Model</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="掩码模型masked-discrete-state-model"><a class="header" href="#掩码模型masked-discrete-state-model">掩码模型(Masked Discrete-State Model)</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="uniform-discrete-state-model"><a class="header" href="#uniform-discrete-state-model">Uniform Discrete-State Model</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="多模态模型multi-modal-model"><a class="header" href="#多模态模型multi-modal-model">多模态模型(Multi-modal Model)</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="生成对抗网络-gan"><a class="header" href="#生成对抗网络-gan">生成对抗网络 (GAN)</a></h1>
<p>生成对抗网络（GAN）是一类重要的生成模型，它通过生成器和判别器的相互博弈来学习数据分布。GAN 的核心思想是通过对抗训练来提升生成质量，使得生成器能够产生逼真的样本。</p>
<h2 id="主要类型-1"><a class="header" href="#主要类型-1">主要类型</a></h2>
<h3 id="连续生成对抗网络-默认"><a class="header" href="#连续生成对抗网络-默认">连续生成对抗网络 (默认)</a></h3>
<p>连续 GAN 使用连续的潜在空间，通过生成器和判别器的相互博弈来提升生成质量。它特别适合处理连续数据，如自然图像。</p>
<p><a href="./gan/continuous.html">了解更多关于连续生成对抗网络</a></p>
<h3 id="向量量化生成对抗网络-vq-gan"><a class="header" href="#向量量化生成对抗网络-vq-gan">向量量化生成对抗网络 (VQ-GAN)</a></h3>
<p>VQ-GAN 结合了 VQ-VAE 和 GAN 的优点，使用离散的潜在表示和对抗训练来提升生成质量。它特别适合处理离散数据，如文本和音频。</p>
<p><a href="./gan/vq-gan.html">了解更多关于向量量化生成对抗网络</a></p>
<h2 id="应用领域-1"><a class="header" href="#应用领域-1">应用领域</a></h2>
<ol>
<li>
<p><strong>图像生成与处理</strong></p>
<ul>
<li>图像生成</li>
<li>图像编辑</li>
<li>风格迁移</li>
<li>超分辨率</li>
</ul>
</li>
<li>
<p><strong>音频处理</strong></p>
<ul>
<li>语音合成</li>
<li>音乐生成</li>
<li>音频增强</li>
</ul>
</li>
<li>
<p><strong>文本生成</strong></p>
<ul>
<li>文本生成</li>
<li>对话系统</li>
<li>机器翻译</li>
</ul>
</li>
<li>
<p><strong>视频生成</strong></p>
<ul>
<li>视频生成</li>
<li>视频编辑</li>
<li>动作迁移</li>
</ul>
</li>
</ol>
<h2 id="发展趋势-1"><a class="header" href="#发展趋势-1">发展趋势</a></h2>
<ol>
<li>
<p><strong>架构改进</strong></p>
<ul>
<li>更稳定的训练策略</li>
<li>更高效的网络结构</li>
<li>更好的生成质量</li>
</ul>
</li>
<li>
<p><strong>训练方法</strong></p>
<ul>
<li>更稳定的优化算法</li>
<li>更好的损失函数设计</li>
<li>更高效的训练策略</li>
</ul>
</li>
<li>
<p><strong>应用扩展</strong></p>
<ul>
<li>多模态生成</li>
<li>可控生成</li>
<li>可解释性研究</li>
</ul>
</li>
</ol>
<h2 id="参考文献-9"><a class="header" href="#参考文献-9">参考文献</a></h2>
<ol>
<li>Goodfellow, I., et al. (2014). Generative adversarial networks.</li>
<li>Arjovsky, M., et al. (2017). Wasserstein GAN.</li>
<li>Esser, P., et al. (2021). Taming transformers for high-resolution image synthesis.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="连续生成对抗网络-continuous-gan"><a class="header" href="#连续生成对抗网络-continuous-gan">连续生成对抗网络 (Continuous GAN)</a></h1>
<p>生成对抗网络（GAN）是一种通过对抗训练来学习数据分布的生成模型。连续 GAN 使用连续的潜在空间，通过生成器和判别器的相互博弈来提升生成质量。</p>
<h2 id="架构-5"><a class="header" href="#架构-5">架构</a></h2>
<p>连续 GAN 由两个主要组件组成：</p>
<ol>
<li><strong>生成器网络</strong>：将随机噪声映射到数据空间</li>
<li><strong>判别器网络</strong>：区分真实数据和生成数据</li>
</ol>
<h2 id="数学框架-4"><a class="header" href="#数学框架-4">数学框架</a></h2>
<h3 id="对抗目标"><a class="header" href="#对抗目标">对抗目标</a></h3>
<p>GAN 的训练目标可以表示为：</p>
<p>[ \min_G \max_D \mathbb{E}<em>{x \sim p</em>{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1-D(G(z)))] ]</p>
<p>其中：</p>
<ul>
<li>( G ) 是生成器</li>
<li>( D ) 是判别器</li>
<li>( p_{data} ) 是真实数据分布</li>
<li>( p_z ) 是潜在空间分布（通常为标准正态分布）</li>
</ul>
<h3 id="训练过程"><a class="header" href="#训练过程">训练过程</a></h3>
<ol>
<li><strong>判别器更新</strong>：最大化判别准确率</li>
<li><strong>生成器更新</strong>：最小化判别准确率</li>
</ol>
<h2 id="变体-4"><a class="header" href="#变体-4">变体</a></h2>
<h3 id="wgan"><a class="header" href="#wgan">WGAN</a></h3>
<p>WGAN 使用 Wasserstein 距离来改善训练稳定性：</p>
<p>[ \min_G \max_{D \in \mathcal{D}} \mathbb{E}<em>{x \sim p</em>{data}}[D(x)] - \mathbb{E}_{z \sim p_z}[D(G(z))] ]</p>
<h3 id="stylegan"><a class="header" href="#stylegan">StyleGAN</a></h3>
<p>StyleGAN 通过风格混合和噪声注入来增强生成多样性。</p>
<h2 id="优势-5"><a class="header" href="#优势-5">优势</a></h2>
<ol>
<li><strong>高质量生成</strong>：可以产生逼真的样本</li>
<li><strong>灵活性</strong>：可以处理各种类型的数据</li>
<li><strong>无监督学习</strong>：不需要标签数据</li>
<li><strong>端到端训练</strong>：可以直接优化生成质量</li>
</ol>
<h2 id="局限性-4"><a class="header" href="#局限性-4">局限性</a></h2>
<ol>
<li><strong>训练不稳定</strong>：需要仔细平衡生成器和判别器</li>
<li><strong>模式崩塌</strong>：可能只生成有限种类的样本</li>
<li><strong>评估困难</strong>：缺乏明确的评估指标</li>
</ol>
<h2 id="应用-5"><a class="header" href="#应用-5">应用</a></h2>
<ol>
<li><strong>图像生成</strong>：创建逼真的图像</li>
<li><strong>图像编辑</strong>：属性编辑和风格迁移</li>
<li><strong>数据增强</strong>：生成训练数据</li>
<li><strong>跨域转换</strong>：图像到图像转换</li>
</ol>
<h2 id="参考文献-10"><a class="header" href="#参考文献-10">参考文献</a></h2>
<ol>
<li>Goodfellow, I., et al. (2014). Generative adversarial networks.</li>
<li>Arjovsky, M., et al. (2017). Wasserstein GAN.</li>
<li>Karras, T., et al. (2019). A style-based generator architecture for generative adversarial networks.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="向量量化生成对抗网络-vq-gan-1"><a class="header" href="#向量量化生成对抗网络-vq-gan-1">向量量化生成对抗网络 (VQ-GAN)</a></h1>
<p>向量量化生成对抗网络（VQ-GAN）结合了 VQ-VAE 和 GAN 的优点，使用离散的潜在表示和对抗训练来提升生成质量。VQ-GAN 通过向量量化将连续特征映射到离散的码本，并利用判别器来优化重建质量。</p>
<h2 id="架构-6"><a class="header" href="#架构-6">架构</a></h2>
<p>VQ-GAN 的主要组件包括：</p>
<ol>
<li><strong>编码器网络</strong>：将输入数据映射到连续特征空间</li>
<li><strong>向量量化层</strong>：将连续特征映射到离散码本</li>
<li><strong>解码器网络</strong>：从量化特征重建数据</li>
<li><strong>判别器网络</strong>：评估重建质量</li>
<li><strong>码本</strong>：包含可学习的离散表示</li>
</ol>
<h2 id="数学框架-5"><a class="header" href="#数学框架-5">数学框架</a></h2>
<h3 id="向量量化过程-1"><a class="header" href="#向量量化过程-1">向量量化过程</a></h3>
<p>给定编码器输出 ( z_e(x) )，VQ-GAN 通过以下步骤进行量化：</p>
<p>[ z_q(x) = \text{VQ}(z_e(x)) = e_k, \quad k = \arg\min_j |z_e(x) - e_j|_2 ]</p>
<h3 id="训练目标-1"><a class="header" href="#训练目标-1">训练目标</a></h3>
<p>VQ-GAN 的训练目标包括：</p>
<ol>
<li><strong>重建损失</strong>：确保解码器能够准确重建输入</li>
<li><strong>对抗损失</strong>：通过判别器提升生成质量</li>
<li><strong>感知损失</strong>：使用预训练网络提取特征进行监督</li>
</ol>
<p>总损失函数为：</p>
<p>[ \mathcal{L}<em>{\text{VQ-GAN}} = \mathcal{L}</em>{\text{recon}} + \lambda_{\text{adv}}\mathcal{L}<em>{\text{adv}} + \lambda</em>{\text{perceptual}}\mathcal{L}_{\text{perceptual}} ]</p>
<h2 id="变体-5"><a class="header" href="#变体-5">变体</a></h2>
<h3 id="vq-gan-2"><a class="header" href="#vq-gan-2">VQ-GAN-2</a></h3>
<p>VQ-GAN-2 通过引入分层结构和多尺度判别器来增强生成能力。</p>
<h3 id="vq-gan-3"><a class="header" href="#vq-gan-3">VQ-GAN-3</a></h3>
<p>VQ-GAN-3 进一步改进了码本设计和训练策略。</p>
<h2 id="优势-6"><a class="header" href="#优势-6">优势</a></h2>
<ol>
<li><strong>高质量生成</strong>：结合了 VQ-VAE 的精确重建和 GAN 的逼真性</li>
<li><strong>离散表示</strong>：更适合处理离散数据</li>
<li><strong>多尺度处理</strong>：可以处理不同尺度的特征</li>
<li><strong>可控生成</strong>：支持基于离散 token 的生成控制</li>
</ol>
<h2 id="局限性-5"><a class="header" href="#局限性-5">局限性</a></h2>
<ol>
<li><strong>计算开销</strong>：需要维护和更新码本</li>
<li><strong>训练复杂度</strong>：需要平衡多个损失项</li>
<li><strong>码本大小限制</strong>：需要预先设定合适的码本大小</li>
</ol>
<h2 id="应用-6"><a class="header" href="#应用-6">应用</a></h2>
<ol>
<li><strong>图像生成</strong>：高质量图像生成和编辑</li>
<li><strong>视频生成</strong>：多帧视频生成</li>
<li><strong>音频处理</strong>：高质量音频生成</li>
<li><strong>文本生成</strong>：基于离散 token 的文本生成</li>
</ol>
<h2 id="参考文献-11"><a class="header" href="#参考文献-11">参考文献</a></h2>
<ol>
<li>Esser, P., et al. (2021). Taming transformers for high-resolution image synthesis.</li>
<li>Yu, J., et al. (2022). Vector-quantized image modeling with improved VQGAN.</li>
<li>Yu, J., et al. (2023). Scaling autoregressive models for content-rich text-to-image generation.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="编程实践"><a class="header" href="#编程实践">编程实践</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="diffusion-model-的实现"><a class="header" href="#diffusion-model-的实现">Diffusion Model 的实现</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="flow-matching-1"><a class="header" href="#flow-matching-1">Flow Matching</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ddim-1"><a class="header" href="#ddim-1">DDIM</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dpm-1"><a class="header" href="#dpm-1">DPM</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="flow-matching-2"><a class="header" href="#flow-matching-2">Flow Matching</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stochastic-interpolants-1"><a class="header" href="#stochastic-interpolants-1">Stochastic Interpolants</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pixelrnn-1"><a class="header" href="#pixelrnn-1">PixelRNN</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chatgpt"><a class="header" href="#chatgpt">ChatGPT</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="agent-composition-1"><a class="header" href="#agent-composition-1">Agent Composition</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="masked-discrete-state-model"><a class="header" href="#masked-discrete-state-model">Masked Discrete-State Model</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multi-modal-model"><a class="header" href="#multi-modal-model">Multi-modal Model</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gan"><a class="header" href="#gan">GAN</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
